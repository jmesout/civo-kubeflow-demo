{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0. Notebook Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"margin-bottom:0px; padding-bottom:0px;\">\n",
    "    <img src=\"https://www.civo.com/assets/logo-28e013cd1630517ca866d2993d8e4258232006dcd30795774d54288396d69c8a.svg\" style=\"width:100px; heigh:100px;\"/>\n",
    "    <h2 style=\"display:inline;\">  - The Cloud Native Service Provider</h2>\n",
    "</span>\n",
    "<img src=\"https://www.civo.com/assets/public/machine-learning/gradient-divider-13b90e98503fdac947c77d8cdb6bf55f3af7186422ff7e4bea759e34eb5767c5.svg\" style=\"width:100%; padding-top:0px margin-top:0px; padding-bottom:0px margin-bottom:0px;\"/>\n",
    "<div>\n",
    "    <b> Quick Links:</b>\n",
    "    <a href=\"https://www.civo.com/\">Civo Home </a> |\n",
    "    <a href=\"https://www.civo.com/docs/machine-learning\">KfaaS Docs </a> |\n",
    "    <a href=\"https://www.civo.com/machine-learning\">Civo Machine Learning </a> |\n",
    "    <a href=\"https://www.civo.com/docs\">Civo Docs </a>\n",
    "</div>\n",
    "\n",
    "<div>\n",
    "    <i>Please Note: This example has been modified by <a href=\"https://www.civo.com/\" target=\"_blank\">civo.com</a> for use with the <strong>Kubeflow as a Service</strong> product. All rights and credit belong to the original authors.</i>\n",
    "</div>\n",
    "<img src=\"https://www.civo.com/assets/public/machine-learning/gradient-divider-13b90e98503fdac947c77d8cdb6bf55f3af7186422ff7e4bea759e34eb5767c5.svg\" style=\"width:100%; padding-top:0px margin-top:0px; padding-bottom:0px margin-bottom:0px;\"/>\n",
    "\n",
    "<div style=\"text-align:center;\">\n",
    "    <h1 style=\"font-weight:bold; margin-top:10px; padding-top:10px; padding-bottom:0px; margin-bottom:0px;\">Civo KfaaS - PyTorch MNIST Tutorial</h1>\n",
    "    <h4 style=\"margin-top:0px; padding-top:0px; padding-bottom:0px; margin-bottom:5px;\">Author: josh@civo.com</h4>\n",
    "    <img src=\"https://miro.medium.com/v2/resize:fit:1200/1*3DUs-90altOgaBcVJ9LTGg.png\" style=\"border-radius:5px; width:60%; padding:20px; padding-top:0px; margin-top:0px;\">\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### üöß Project Description:\n",
    "- The MNIST example in the PyTorch examples repository is a basic introduction to training a simple convolutional neural network (CNN) on the MNIST dataset. The MNIST dataset contains handwritten digits and is a standard dataset used in the machine learning community for benchmarking and introduction to deep learning.\n",
    "### üìà Dataset:\n",
    "- The MNIST dataset is composed of 28x28 grayscale images of handwritten digits (from 0 to 9).\n",
    "It is split into 60,000 training images and 10,000 test images.\n",
    "### üß† Neural Network Architecture:\n",
    "- The example typically employs a simple CNN architecture. This network has a few convolutional layers followed by fully connected layers. Activation functions like ReLU and techniques such as max-pooling may be used in between these layers.\n",
    "Dropout might also be utilized to prevent overfitting.\n",
    "### üèÉ‚Äç‚ôÄÔ∏è Training:\n",
    "- The network is trained using a common optimization algorithm, such as Stochastic Gradient Descent (SGD), to minimize a loss function (e.g., cross-entropy loss for classification tasks). The training loop includes forward propagation, loss computation, backpropagation, and optimization steps.\n",
    "### üß™ Evaluation:\n",
    "- After training, the network is evaluated on the test dataset to determine its accuracy in recognizing handwritten digits that it hasn't seen during training.\n",
    "### ‚öôÔ∏è Configurations/Parameters:\n",
    "- The code usually supports various ways to modify hyperparameters, such as learning rate, batch size, number of epochs, etc. This flexibility makes it easier to experiment with different settings.\n",
    "### üõ†Ô∏è Dependencies:\n",
    "- The primary dependency is PyTorch, the deep learning framework on which the example is built. Additionally, torchvision might be used for dataset loading and transformations.\n",
    "### üìù References:\n",
    "- https://github.com/pytorch/examples/blob/main/mnist/main.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. KfaaS Setup\n",
    "<img src=\"https://www.civo.com/assets/public/machine-learning/gradient-divider-13b90e98503fdac947c77d8cdb6bf55f3af7186422ff7e4bea759e34eb5767c5.svg\" style=\"width:100%; padding-top:0px margin-top:0px; padding-bottom:0px margin-bottom:0px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please refer to: XXXXXX  for information regarding the setup of your KfaaS Cluster"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Environment Setup \n",
    "<img src=\"https://www.civo.com/assets/public/machine-learning/gradient-divider-13b90e98503fdac947c77d8cdb6bf55f3af7186422ff7e4bea759e34eb5767c5.svg\" style=\"width:100%; padding-top:0px margin-top:0px; padding-bottom:0px margin-bottom:0px;\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install the Python Packages in requirements.txt\n",
    "! pip install -U -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure compatibility between Python 2 and Python 3.\n",
    "# This allows the use of the print function from Python 3 in Python 2.\n",
    "# It's a good practice for Python 2 and 3 interoperability, but it's less relevant now as Python 2 is officially retired.\n",
    "from __future__ import print_function\n",
    "\n",
    "# Import the main PyTorch library. It provides tensor computation and deep neural networks.\n",
    "import torch\n",
    "\n",
    "# Import the neural network module from PyTorch. \n",
    "# This provides classes to build and train neural networks.\n",
    "import torch.nn as nn\n",
    "\n",
    "# Import the functional API of PyTorch's neural network module.\n",
    "# This provides functions (like activation functions and loss functions) that don't have any parameters.\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# Import the optimization module from PyTorch.\n",
    "# This provides common optimization algorithms like SGD, Adam, and Adadelta.\n",
    "import torch.optim as optim\n",
    "\n",
    "# Import datasets and transformations from torchvision.\n",
    "# Torchvision is a library that provides popular datasets, model architectures, and image transformations for computer vision.\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "# Import the learning rate scheduler from PyTorch's optimization module.\n",
    "# This allows for changing the learning rate during training based on the number of epochs.\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "\n",
    "# import the matplotlib plotting library to plot the loss and accuracy curves.\n",
    "# this is not required for training the model, but it's useful to visualize the model.\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import torch.nn.functional as F\n",
    "import torch\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import itertools\n",
    "\n",
    "from tqdm import tqdm\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Define Parameters\n",
    "<img src=\"https://www.civo.com/assets/public/machine-learning/gradient-divider-13b90e98503fdac947c77d8cdb6bf55f3af7186422ff7e4bea759e34eb5767c5.svg\" style=\"width:100%; padding-top:0px margin-top:0px; padding-bottom:0px margin-bottom:0px;\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Params:\n",
    "    def __init__(self):\n",
    "        # The number of training examples in one forward/backward pass (one iteration).\n",
    "        # The higher the batch size, the more memory required.\n",
    "        self.batch_size = 64\n",
    "\n",
    "        # The number of test examples used in one forward pass when evaluating the model.\n",
    "        # Typically, a larger batch size can be used for testing as backpropagation (which requires more memory) is not performed.\n",
    "        self.test_batch_size = 1000\n",
    "\n",
    "        # Number of times the entire training dataset will be presented to the model.\n",
    "        # One epoch means one forward and one backward pass of all training examples.\n",
    "        self.epochs = 14\n",
    "\n",
    "        # Learning rate for the optimizer. Determines the step size at each iteration \n",
    "        # while moving towards a minimum of the loss function.\n",
    "        self.lr = 1.0\n",
    "\n",
    "        # Used for learning rate scheduling. \n",
    "        # The learning rate is multiplied by this factor after each epoch.\n",
    "        # Values usually between 0 and 1 to decrease the learning rate over epochs.\n",
    "        self.gamma = 0.7\n",
    "\n",
    "        # If set to True, it will disable training on CUDA (GPU) even if it's available.\n",
    "        # Useful for debugging on CPU or in environments without a GPU.\n",
    "        self.no_cuda = False\n",
    "\n",
    "        # If set to True, it will disable training on macOS GPU.\n",
    "        # Specific to environments running macOS with GPU capabilities.\n",
    "        self.no_mps = False\n",
    "\n",
    "        # If set to True, only one batch of the training data will be used.\n",
    "        # Useful for quickly checking if the training loop works.\n",
    "        self.dry_run = False\n",
    "\n",
    "        # Seed for generating random numbers. \n",
    "        # Ensures reproducibility across runs if other factors remain constant.\n",
    "        self.seed = 1\n",
    "\n",
    "        # Determines how often training progress (loss value) will be printed to the console.\n",
    "        # For example, if set to 10, every 10 batches the training loss will be printed.\n",
    "        self.log_interval = 10\n",
    "\n",
    "        # If set to True, the trained model will be saved to disk.\n",
    "        self.save_model = False\n",
    "\n",
    "args = Params()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Visualise Parameters\n",
    "<img src=\"https://www.civo.com/assets/public/machine-learning/gradient-divider-13b90e98503fdac947c77d8cdb6bf55f3af7186422ff7e4bea759e34eb5767c5.svg\" style=\"width:100%; padding-top:0px margin-top:0px; padding-bottom:0px margin-bottom:0px;\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the parameters and their bounds for hyperparameter optimization\n",
    "params = {\n",
    "    \"batch_size\": [1, 512],\n",
    "    \"test_batch_size\": [1, 5000],\n",
    "    \"epochs\": [1, 100],\n",
    "    \"lr\": [0.001, 10.0],\n",
    "    \"gamma\": [0.1, 1.0],\n",
    "    \"no_cuda\": [0, 1],\n",
    "    \"no_mps\": [0, 1],\n",
    "    \"dry_run\": [0, 1],\n",
    "    \"seed\": [0, 100],\n",
    "    \"log_interval\": [1, 100],\n",
    "    \"save_model\": [0, 1]\n",
    "}\n",
    "\n",
    "# Extract the actual values of the parameters from an assumed 'args' object\n",
    "values = {\n",
    "    \"batch_size\": args.batch_size,\n",
    "    \"test_batch_size\": args.test_batch_size,\n",
    "    \"epochs\": args.epochs,\n",
    "    \"lr\": args.lr,\n",
    "    \"gamma\": args.gamma,\n",
    "    \"no_cuda\": int(args.no_cuda),\n",
    "    \"no_mps\": int(args.no_mps),\n",
    "    \"dry_run\": int(args.dry_run),\n",
    "    \"seed\": args.seed,\n",
    "    \"log_interval\": args.log_interval,\n",
    "    \"save_model\": int(args.save_model)\n",
    "}\n",
    "\n",
    "# Get the list of parameter names for further processing\n",
    "params_names = list(params.keys())\n",
    "\n",
    "# Compute the normalized values of the parameters based on their bounds\n",
    "normalized_values = {param: (values[param] - params[param][0]) / (params[param][1] - params[param][0]) \n",
    "                     for param in params_names}\n",
    "\n",
    "# Set up dictionaries to map boolean values to colors and labels for visualization\n",
    "bool_colors = {\n",
    "    True: \"green\",\n",
    "    False: \"red\"\n",
    "}\n",
    "bool_labels = {\n",
    "    True: \"On\",\n",
    "    False: \"Off\"\n",
    "}\n",
    "\n",
    "# Initialize a figure for plotting the parameters\n",
    "fig, ax = plt.subplots(figsize=(12, 8))\n",
    "\n",
    "# Create visualization bars for each parameter\n",
    "for param in params_names:\n",
    "    if param in [\"no_cuda\", \"no_mps\", \"dry_run\", \"save_model\"]:\n",
    "        # Handle boolean parameters\n",
    "        bar = ax.bar(param, 1, color=bool_colors[bool(values[param])])\n",
    "        ax.text(bar[0].get_x() + bar[0].get_width() / 2, 0.5, bool_labels[bool(values[param])],\n",
    "                ha='center', va='center', color='white', fontsize=10)\n",
    "    else:\n",
    "        # Handle numeric parameters\n",
    "        bar = ax.bar(param, 1, color='lightblue')\n",
    "        height = normalized_values[param]\n",
    "        # Draw a red line indicating the normalized value of the parameter\n",
    "        ax.plot([bar[0].get_x(), bar[0].get_x() + bar[0].get_width()], [height, height], color=\"red\", lw=2)\n",
    "        # Display the actual normalized value above the red line\n",
    "        ax.text(bar[0].get_x() + bar[0].get_width() / 2, height + 0.05, str(round(height, 2)), ha='center', va='center', color='black', fontsize=10)\n",
    "\n",
    "# Set title and labels\n",
    "ax.set_title('Normalized Parameters Visualization')\n",
    "ax.set_ylabel('Normalized Values')\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.tight_layout()\n",
    "# Display the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Create Neural Network\n",
    "<img src=\"https://www.civo.com/assets/public/machine-learning/gradient-divider-13b90e98503fdac947c77d8cdb6bf55f3af7186422ff7e4bea759e34eb5767c5.svg\" style=\"width:100%; padding-top:0px margin-top:0px; padding-bottom:0px margin-bottom:0px;\"/>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"font-family: 'Roboto', sans-serif; border:0px solid #e0e0e0; width: 80%; box-shadow: 0 4px 8px 0 rgba(0, 0, 0, 0.2);\">\n",
    "    <h3 style=\"margin-bottom:0px; padding-bottom:0px;\" >Neural Network Architecture:</h3>\n",
    "    <div style=\"border-radius: 8px; overflow: hidden;  box-shadow: 0 4px 8px 0 rgba(0, 0, 0, 0.1); background-color: #ffffff; margin-top: 20px; width:95%;\">\n",
    "        <table border=\"0\" cellpadding=\"5\" style=\"border-collapse: collapse; width:100%; margin-top: 20px;\">\n",
    "            <tr>\n",
    "                <td colspan=\"2\" style=\"background-color: #f5f5f5;  color: #616161;\">Input Image (1 channel)</td>\n",
    "            </tr>\n",
    "            <tr>\n",
    "                <td style=\"background-color: #ECEFF1; text-align:center; color: #616161;\">Conv1</td>\n",
    "                <td style=\"color: #757575;\">Convolution (1 to 32 channels, 3x3 kernel)</td>\n",
    "            </tr>\n",
    "            <tr>\n",
    "                <td style=\"background-color: #ECEFF1; text-align:center; color: #616161;\">ReLU</td>\n",
    "                <td style=\"color: #757575;\">Activation Function</td>\n",
    "            </tr>\n",
    "            <tr>\n",
    "                <td style=\"background-color: #ECEFF1; text-align:center; color: #616161;\">Conv2</td>\n",
    "                <td style=\"color: #757575;\">Convolution (32 to 64 channels, 3x3 kernel)</td>\n",
    "            </tr>\n",
    "            <tr>\n",
    "                <td style=\"background-color: #ECEFF1; text-align:center; color: #616161;\">ReLU</td>\n",
    "                <td style=\"color: #757575;\">Activation Function</td>\n",
    "            </tr>\n",
    "            <tr>\n",
    "                <td style=\"background-color: #ECEFF1; text-align:center; color: #616161;\">Max Pool</td>\n",
    "                <td style=\"color: #757575;\">Max Pooling (2x2 window)</td>\n",
    "            </tr>\n",
    "            <tr>\n",
    "                <td style=\"background-color: #ECEFF1; text-align:center; color: #616161;\">Dropout1</td>\n",
    "                <td style=\"color: #757575;\">25% Dropout</td>\n",
    "            </tr>\n",
    "            <tr>\n",
    "                <td style=\"background-color: #ECEFF1; text-align:center; color: #616161;\">Flatten</td>\n",
    "                <td style=\"color: #757575;\">Flatten tensor</td>\n",
    "            </tr>\n",
    "            <tr>\n",
    "                <td style=\"background-color: #ECEFF1; text-align:center; color: #616161;\">FC1</td>\n",
    "                <td style=\"color: #757575;\">Fully Connected (9216 to 128)</td>\n",
    "            </tr>\n",
    "            <tr>\n",
    "                <td style=\"background-color: #ECEFF1; text-align:center; color: #616161;\">ReLU</td>\n",
    "                <td style=\"color: #757575;\">Activation Function</td>\n",
    "            </tr>\n",
    "            <tr>\n",
    "                <td style=\"background-color: #ECEFF1; text-align:center; color: #616161;\">Dropout2</td>\n",
    "                <td style=\"color: #757575;\">50% Dropout</td>\n",
    "            </tr>\n",
    "            <tr>\n",
    "                <td style=\"background-color: #ECEFF1; text-align:center; color: #616161;\">FC2</td>\n",
    "                <td style=\"color: #757575;\">Fully Connected (128 to 10)</td>\n",
    "            </tr>\n",
    "<tr>\n",
    "            <td colspan=\"2\" style=\"background-color: #f5f5f5; text-align:center; padding: 20px 0; color: #616161;\">\n",
    "                Output Classes (Log Probabilities)\n",
    "                <div style=\"margin-top:20px; display: flex; justify-content: space-between;\">\n",
    "                    <svg height=\"30\" width=\"300\">\n",
    "                        <g transform=\"translate(0,0)\">\n",
    "                            <rect x=\"0\" y=\"10\" width=\"28\" height=\"10\" style=\"fill:#ECEFF1;stroke-width:1;stroke:#CFD8DC\" />\n",
    "                            <text x=\"14\" y=\"18\" fill=\"#616161\" font-size=\"10\" text-anchor=\"middle\">0</text>\n",
    "                        </g>\n",
    "                        <g transform=\"translate(30,0)\">\n",
    "                            <rect x=\"0\" y=\"10\" width=\"28\" height=\"10\" style=\"fill:#ECEFF1;stroke-width:1;stroke:#CFD8DC\" />\n",
    "                            <text x=\"14\" y=\"18\" fill=\"#616161\" font-size=\"10\" text-anchor=\"middle\">1</text>\n",
    "                        </g>\n",
    "                        <g transform=\"translate(60,0)\">\n",
    "                            <rect x=\"0\" y=\"10\" width=\"28\" height=\"10\" style=\"fill:#ECEFF1;stroke-width:1;stroke:#CFD8DC\" />\n",
    "                            <text x=\"14\" y=\"18\" fill=\"#616161\" font-size=\"10\" text-anchor=\"middle\">2</text>\n",
    "                        </g>\n",
    "                        <g transform=\"translate(90,0)\">\n",
    "                            <rect x=\"0\" y=\"10\" width=\"28\" height=\"10\" style=\"fill:#ECEFF1;stroke-width:1;stroke:#CFD8DC\" />\n",
    "                            <text x=\"14\" y=\"18\" fill=\"#616161\" font-size=\"10\" text-anchor=\"middle\">3</text>\n",
    "                        </g>\n",
    "                        <g transform=\"translate(120,0)\">\n",
    "                            <rect x=\"0\" y=\"10\" width=\"28\" height=\"10\" style=\"fill:#ECEFF1;stroke-width:1;stroke:#CFD8DC\" />\n",
    "                            <text x=\"14\" y=\"18\" fill=\"#616161\" font-size=\"10\" text-anchor=\"middle\">4</text>\n",
    "                        </g>\n",
    "                        <g transform=\"translate(150,0)\">\n",
    "                            <rect x=\"0\" y=\"10\" width=\"28\" height=\"10\" style=\"fill:#ECEFF1;stroke-width:1;stroke:#CFD8DC\" />\n",
    "                            <text x=\"14\" y=\"18\" fill=\"#616161\" font-size=\"10\" text-anchor=\"middle\">5</text>\n",
    "                        </g>\n",
    "                        <g transform=\"translate(180,0)\">\n",
    "                            <rect x=\"0\" y=\"10\" width=\"28\" height=\"10\" style=\"fill:#ECEFF1;stroke-width:1;stroke:#CFD8DC\" />\n",
    "                            <text x=\"14\" y=\"18\" fill=\"#616161\" font-size=\"10\" text-anchor=\"middle\">6</text>\n",
    "                        </g>\n",
    "                        <g transform=\"translate(210,0)\">\n",
    "                            <rect x=\"0\" y=\"10\" width=\"28\" height=\"10\" style=\"fill:#ECEFF1;stroke-width:1;stroke:#CFD8DC\" />\n",
    "                            <text x=\"14\" y=\"18\" fill=\"#616161\" font-size=\"10\" text-anchor=\"middle\">7</text>\n",
    "                        </g>\n",
    "                        <g transform=\"translate(240,0)\">\n",
    "                            <rect x=\"0\" y=\"10\" width=\"28\" height=\"10\" style=\"fill:#ECEFF1;stroke-width:1;stroke:#CFD8DC\" />\n",
    "                            <text x=\"14\" y=\"18\" fill=\"#616161\" font-size=\"10\" text-anchor=\"middle\">8</text>\n",
    "                        </g>\n",
    "                        <g transform=\"translate(270,0)\">\n",
    "                            <rect x=\"0\" y=\"10\" width=\"28\" height=\"10\" style=\"fill:#ECEFF1;stroke-width:1;stroke:#CFD8DC\" />\n",
    "                            <text x=\"14\" y=\"18\" fill=\"#616161\" font-size=\"10\" text-anchor=\"middle\">9</text>\n",
    "                        </g>\n",
    "                    </svg>\n",
    "                </div>\n",
    "            </td>\n",
    "        </tr>\n",
    "        </table>\n",
    "    </div>\n",
    "    Lora ipsum write some text in heree....\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "\n",
    "        # Convolutional layer\n",
    "        # Parameters:\n",
    "        # - Number of input channels: 1 (assuming grayscale images)\n",
    "        # - Number of output channels (filters): 32\n",
    "        # - Kernel size: 3x3\n",
    "        # - Stride: 1 (default)\n",
    "        self.conv1 = nn.Conv2d(1, 32, 3, 1)\n",
    "\n",
    "        # Convolutional layer\n",
    "        # Parameters:\n",
    "        # - Number of input channels: 32 (from previous layer)\n",
    "        # - Number of output channels (filters): 64\n",
    "        # - Kernel size: 3x3\n",
    "        # - Stride: 1 (default)\n",
    "        self.conv2 = nn.Conv2d(32, 64, 3, 1)\n",
    "\n",
    "        # Dropout layer to prevent overfitting\n",
    "        # Drops out 25% of the input units randomly to prevent overfitting\n",
    "        self.dropout1 = nn.Dropout(0.25)\n",
    "\n",
    "        # Dropout layer to prevent overfitting\n",
    "        # Drops out 50% of the input units randomly to prevent overfitting\n",
    "        self.dropout2 = nn.Dropout(0.5)\n",
    "\n",
    "        # Fully connected (dense) layer\n",
    "        # Parameters:\n",
    "        # - Number of input features: 9216 (resulting from the previous layers)\n",
    "        # - Number of output features: 128\n",
    "        self.fc1 = nn.Linear(9216, 128)\n",
    "\n",
    "        # Fully connected (dense) layer\n",
    "        # Parameters:\n",
    "        # - Number of input features: 128 (from previous layer)\n",
    "        # - Number of output features: 10 (assuming 10 classes for classification)\n",
    "        self.fc2 = nn.Linear(128, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Passing input through the first convolutional layer\n",
    "        x = self.conv1(x)\n",
    "        # Applying ReLU (Rectified Linear Unit) activation function\n",
    "        x = F.relu(x)\n",
    "\n",
    "        # Passing through the second convolutional layer\n",
    "        x = self.conv2(x)\n",
    "        # Applying ReLU activation function\n",
    "        x = F.relu(x)\n",
    "\n",
    "        # Applying max pooling with a 2x2 window size to reduce spatial dimensions\n",
    "        x = F.max_pool2d(x, 2)\n",
    "\n",
    "        # Applying the first dropout layer\n",
    "        x = self.dropout1(x)\n",
    "\n",
    "        # Flattening the tensor for the fully connected layers\n",
    "        x = torch.flatten(x, 1)\n",
    "\n",
    "        # Passing through the first fully connected layer\n",
    "        x = self.fc1(x)\n",
    "        # Applying ReLU activation function\n",
    "        x = F.relu(x)\n",
    "\n",
    "        # Applying the second dropout layer\n",
    "        x = self.dropout2(x)\n",
    "\n",
    "        # Passing through the second fully connected layer\n",
    "        x = self.fc2(x)\n",
    "\n",
    "        # Applying the log softmax activation to get log probabilities for each class\n",
    "        # Setting dim=1 ensures that the softmax is applied across the correct dimension\n",
    "        output = F.log_softmax(x, dim=1)\n",
    "\n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Create Training and Testing Functions\n",
    "<img src=\"https://www.civo.com/assets/public/machine-learning/gradient-divider-13b90e98503fdac947c77d8cdb6bf55f3af7186422ff7e4bea759e34eb5767c5.svg\" style=\"width:100%; padding-top:0px margin-top:0px; padding-bottom:0px margin-bottom:0px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"font-family: 'Roboto', sans-serif; border:0px solid #e0e0e0; width: 80%; box-shadow: 0 4px 8px 0 rgba(0, 0, 0, 0.2)\">\n",
    "    <h3 style=\"margin-bottom:0px; padding-bottom:0px;\" >Training Function:</h3>\n",
    "        <table border=\"0\" cellpadding=\"5\" style=\"border-collapse: collapse; width:100%;\">\n",
    "            <tr>\n",
    "                <td style=\"background-color: #ECEFF1; text-align:center; color: #616161;\">Function Signature</td>\n",
    "                <td style=\"color: #757575;\">def train(args, model, device, train_loader, optimizer, epoch):</td>\n",
    "            </tr>\n",
    "            <tr>\n",
    "                <td style=\"background-color: #ECEFF1; text-align:center; color: #616161;\">Set Model Mode</td>\n",
    "                <td style=\"color: #757575;\">model.train()</td>\n",
    "            </tr>\n",
    "            <tr>\n",
    "                <td style=\"background-color: #ECEFF1; text-align:center; color: #616161;\">Training Loop</td>\n",
    "                <td style=\"color: #757575;\">For each batch in train_loader:</td>\n",
    "            </tr>\n",
    "            <tr>\n",
    "                <td style=\"background-color: #ECEFF1; text-align:center; color: #616161;\">Data Transfer</td>\n",
    "                <td style=\"color: #757575;\">Transfer data and target to device</td>\n",
    "            </tr>\n",
    "            <tr>\n",
    "                <td style=\"background-color: #ECEFF1; text-align:center; color: #616161;\">Zero Gradients</td>\n",
    "                <td style=\"color: #757575;\">optimizer.zero_grad()</td>\n",
    "            </tr>\n",
    "            <tr>\n",
    "                <td style=\"background-color: #ECEFF1; text-align:center; color: #616161;\">Forward Pass</td>\n",
    "                <td style=\"color: #757575;\">Compute predictions: output = model(data)</td>\n",
    "            </tr>\n",
    "            <tr>\n",
    "                <td style=\"background-color: #ECEFF1; text-align:center; color: #616161;\">Compute Loss</td>\n",
    "                <td style=\"color: #757575;\">loss = F.nll_loss(output, target)</td>\n",
    "            </tr>\n",
    "            <tr>\n",
    "                <td style=\"background-color: #ECEFF1; text-align:center; color: #616161;\">Backward Pass</td>\n",
    "                <td style=\"color: #757575;\">Compute gradients: loss.backward()</td>\n",
    "            </tr>\n",
    "            <tr>\n",
    "                <td style=\"background-color: #ECEFF1; text-align:center; color: #616161;\">Optimization Step</td>\n",
    "                <td style=\"color: #757575;\">optimizer.step()</td>\n",
    "            </tr>\n",
    "            <tr>\n",
    "                <td style=\"background-color: #ECEFF1; text-align:center; color: #616161;\">Logging</td>\n",
    "                <td style=\"color: #757575;\">Print logs at specified intervals</td>\n",
    "            </tr>\n",
    "            <tr>\n",
    "                <td style=\"background-color: #ECEFF1; text-align:center; color: #616161;\">Dry Run Check</td>\n",
    "                <td style=\"color: #757575;\">Exit loop if dry_run is set to True</td>\n",
    "            </tr>\n",
    "        </table>\n",
    "    </div>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(args, model, device, train_loader, optimizer, epoch):\n",
    "    # Setting the model in training mode.\n",
    "    # This is important for layers like dropout and batch normalization\n",
    "    # which behave differently during training and evaluation.\n",
    "    model.train()\n",
    "    \n",
    "    # Initialize a progress bar using tqdm. Wrapping the train_loader with tqdm will handle the progress bar updates.\n",
    "    pbar = tqdm(train_loader, desc=f\"Epoch {epoch}\")\n",
    "    \n",
    "    # Loop over each batch from the training set\n",
    "    for batch_idx, (data, target) in enumerate(pbar):\n",
    "        \n",
    "        # Transfer data and target labels to the given device (either CPU or GPU)\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        \n",
    "        # Zero out gradients from the previous iteration.\n",
    "        # In PyTorch, gradients accumulate, so they need to be reset on each iteration.\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Forward pass: compute predicted outputs by passing inputs to the model\n",
    "        output = model(data)\n",
    "        \n",
    "        # Compute the negative log likelihood loss between the model output and the actual targets.\n",
    "        loss = F.nll_loss(output, target)\n",
    "        \n",
    "        # Backward pass: compute gradient of the loss with respect to model parameters\n",
    "        loss.backward()\n",
    "        \n",
    "        # Perform a single optimization step (parameter update)\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Update the progress bar description with the current loss\n",
    "        pbar.set_description(f\"Epoch {epoch} Loss: {loss.item():.6f}\")\n",
    "        \n",
    "        # If dry_run is set, exit after the first batch to quickly check the training loop\n",
    "        if args.dry_run:\n",
    "            break\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"font-family: 'Roboto', sans-serif; border:0px solid #e0e0e0; width: 80%; box-shadow: 0 4px 8px 0 rgba(0, 0, 0, 0.2)\">\n",
    "    <h3 style=\"margin-bottom:0px; padding-bottom:0px;\" >Test Function:</h3>\n",
    "        <table border=\"0\" cellpadding=\"5\" style=\"border-collapse: collapse; width:100%;\">\n",
    "            <tr>\n",
    "                <td style=\"background-color: #ECEFF1; text-align:center; color: #616161;\">Function Signature</td>\n",
    "                <td style=\"color: #757575;\">def test(model, device, test_loader):</td>\n",
    "            </tr>\n",
    "            <tr>\n",
    "                <td style=\"background-color: #ECEFF1; text-align:center; color: #616161;\">Set Model Mode</td>\n",
    "                <td style=\"color: #757575;\">model.eval()</td>\n",
    "            </tr>\n",
    "            <tr>\n",
    "                <td style=\"background-color: #ECEFF1; text-align:center; color: #616161;\">Initialize Test Loss</td>\n",
    "                <td style=\"color: #757575;\">test_loss = 0</td>\n",
    "            </tr>\n",
    "            <tr>\n",
    "                <td style=\"background-color: #ECEFF1; text-align:center; color: #616161;\">Initialize Correct Count</td>\n",
    "                <td style=\"color: #757575;\">correct = 0</td>\n",
    "            </tr>\n",
    "            <tr>\n",
    "                <td style=\"background-color: #ECEFF1; text-align:center; color: #616161;\">Evaluation Loop</td>\n",
    "                <td style=\"color: #757575;\">For each batch in test_loader (with gradients disabled):</td>\n",
    "            </tr>\n",
    "            <tr>\n",
    "                <td style=\"background-color: #ECEFF1; text-align:center; color: #616161;\">Data Transfer</td>\n",
    "                <td style=\"color: #757575;\">Transfer data and target to device</td>\n",
    "            </tr>\n",
    "            <tr>\n",
    "                <td style=\"background-color: #ECEFF1; text-align:center; color: #616161;\">Forward Pass</td>\n",
    "                <td style=\"color: #757575;\">Compute predictions: output = model(data)</td>\n",
    "            </tr>\n",
    "            <tr>\n",
    "                <td style=\"background-color: #ECEFF1; text-align:center; color: #616161;\">Compute Loss</td>\n",
    "                <td style=\"color: #757575;\">Sum up the batch loss: test_loss += F.nll_loss(output, target, reduction='sum').item()</td>\n",
    "            </tr>\n",
    "            <tr>\n",
    "                <td style=\"background-color: #ECEFF1; text-align:center; color: #616161;\">Predicted Label</td>\n",
    "                <td style=\"color: #757575;\">Get index of max log-probability: pred = output.argmax(dim=1, keepdim=True)</td>\n",
    "            </tr>\n",
    "            <tr>\n",
    "                <td style=\"background-color: #ECEFF1; text-align:center; color: #616161;\">Count Correct Predictions</td>\n",
    "                <td style=\"color: #757575;\">Count matching predictions: correct += pred.eq(target.view_as(pred)).sum().item()</td>\n",
    "            </tr>\n",
    "            <tr>\n",
    "                <td style=\"background-color: #ECEFF1; text-align:center; color: #616161;\">Average Test Loss</td>\n",
    "                <td style=\"color: #757575;\">Average the loss over the dataset: test_loss /= len(test_loader.dataset)</td>\n",
    "            </tr>\n",
    "            <tr>\n",
    "                <td style=\"background-color: #ECEFF1; text-align:center; color: #616161;\">Print Results</td>\n",
    "                <td style=\"color: #757575;\">Print test loss and accuracy</td>\n",
    "            </tr>\n",
    "        </table>\n",
    "    </div>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(cm, classes, normalize=False, title='Confusion matrix', cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        # print(\"Normalized confusion matrix\")\n",
    "    # else:\n",
    "        # print('Confusion matrix, without normalization')\n",
    "\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, device, test_loader):\n",
    "    # Setting the model in evaluation mode. \n",
    "    # This is important for layers like dropout and batch normalization \n",
    "    # which behave differently during training and evaluation.\n",
    "    model.eval()\n",
    "\n",
    "    # Initialize the test loss to zero\n",
    "    test_loss = 0\n",
    "\n",
    "    # Initialize a count of the number of correct predictions to zero\n",
    "    correct = 0\n",
    "    \n",
    "    # List to store all the predictions and true labels to compute confusion matrix\n",
    "    all_preds = []\n",
    "    all_targets = []\n",
    "\n",
    "    # Disable gradient computations. \n",
    "    # Since we're only doing forward passes during testing, \n",
    "    # we don't need to compute gradients which speeds up the process.\n",
    "    with torch.no_grad():\n",
    "        # Loop over each batch from the test set\n",
    "        for data, target in test_loader:\n",
    "            # Transfer data and target labels to the given device (either CPU or GPU)\n",
    "            data, target = data.to(device), target.to(device)\n",
    "\n",
    "            # Forward pass: compute predicted outputs by passing inputs to the model\n",
    "            output = model(data)\n",
    "\n",
    "            # Sum up the negative log likelihood loss for the entire test set\n",
    "            test_loss += F.nll_loss(output, target, reduction='sum').item()\n",
    "\n",
    "            # Get the index of the maximum log-probability as the predicted label\n",
    "            pred = output.argmax(dim=1, keepdim=True)\n",
    "\n",
    "            # Append the predictions and true labels for the batch to the respective lists\n",
    "            all_preds.extend(pred.cpu().numpy())\n",
    "            all_targets.extend(target.cpu().numpy())\n",
    "\n",
    "            # Count how many predictions match the actual target labels\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "    # Average the total loss over the number of samples in the test set\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "\n",
    "    # Print the average test loss and the accuracy of the model on the test set\n",
    "\n",
    "    # Compute the confusion matrix using sklearn's utility function\n",
    "    cm = confusion_matrix(all_targets, all_preds)\n",
    "    # Define the class names for MNIST dataset\n",
    "    class_names = [str(i) for i in range(10)]\n",
    "    # Plot the confusion matrix\n",
    "    \n",
    "    print('Test Data Set Results:\\n')\n",
    "    print('\\t Average loss: \\t {:.4f},\\n Accuracy: \\t {}/{} ({:.0f}%)\\n'.format(test_loss, correct, len(test_loader.dataset), 100. * correct / len(test_loader.dataset)))\n",
    "    print(cm[0])\n",
    "    # plot_confusion_matrix(cm, class_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Initialise the Processing Device\n",
    "<img src=\"https://www.civo.com/assets/public/machine-learning/gradient-divider-13b90e98503fdac947c77d8cdb6bf55f3af7186422ff7e4bea759e34eb5767c5.svg\" style=\"width:100%; padding-top:0px margin-top:0px; padding-bottom:0px margin-bottom:0px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"padding-left:20px;\">\n",
    "\n",
    "<div style=\"width:100%; text-align:center; border-radius:5px;\">\n",
    "<h3 style=\"margin-bottom:0px; padding-bottom:0px;\" >PyTorch GPU Architecture:</h3>\n",
    "    <img src=\"https://cnvrg.io/wp-content/uploads/2021/01/data-batch.png\" style=\"width:600px; background-color:white;\"> </img>\n",
    "</div>\n",
    "\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: maybe move to setup?????\n",
    "\n",
    "# Determine if CUDA (NVIDIA's parallel computing platform and programming model) should be used.\n",
    "# `use_cuda` will be True if the user hasn't disabled CUDA with `args.no_cuda` and if CUDA is available on the machine.\n",
    "use_cuda = not args.no_cuda and torch.cuda.is_available()\n",
    "\n",
    "# Determine if MPS (Metal Performance Shaders) should be used. \n",
    "# MPS is specific to Apple devices. `use_mps` will be True if the user hasn't disabled MPS with `args.no_mps` \n",
    "# and if MPS is available on the machine.\n",
    "use_mps = not args.no_mps and torch.backends.mps.is_available()\n",
    "\n",
    "# Set the seed for generating random numbers in PyTorch. \n",
    "# This ensures that results are reproducible if all other configurations and the dataset remain constant.\n",
    "torch.manual_seed(args.seed)\n",
    "\n",
    "# Decide on which device the computations will be performed. \n",
    "# The device can be CUDA (GPU), MPS (Apple's GPU), or CPU based on availability and user's preference.\n",
    "if use_cuda:\n",
    "    device = torch.device(\"cuda\")\n",
    "elif use_mps:\n",
    "    device = torch.device(\"mps\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Create Data Loaders\n",
    "<img src=\"https://www.civo.com/assets/public/machine-learning/gradient-divider-13b90e98503fdac947c77d8cdb6bf55f3af7186422ff7e4bea759e34eb5767c5.svg\" style=\"width:100%; padding-top:0px margin-top:0px; padding-bottom:0px margin-bottom:0px;\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Create a dictionary to hold training settings, starting with batch size.\n",
    "train_kwargs = {'batch_size': args.batch_size}\n",
    "\n",
    "# Create a dictionary to hold test settings, starting with batch size.\n",
    "test_kwargs = {'batch_size': args.test_batch_size}\n",
    "\n",
    "# If CUDA is being used, additional arguments related to CUDA are added to both training and test settings.\n",
    "# These ensure efficient data transfer between CPU and GPU.\n",
    "if use_cuda:\n",
    "    cuda_kwargs = {'num_workers': 1,       # Number of subprocesses to use for data loading. \n",
    "                                            # 1 means data loading will be done in the main process.\n",
    "                   'pin_memory': True,      # Pin memory ensures faster data transfer from CPU to CUDA.\n",
    "                   'shuffle': True}         # Shuffle the dataset before training. \n",
    "                                            # This provides a random order of data input for each epoch.\n",
    "    \n",
    "    # Update training and test settings with the additional CUDA-related settings.\n",
    "    train_kwargs.update(cuda_kwargs)\n",
    "    test_kwargs.update(cuda_kwargs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"font-family: 'Roboto', sans-serif; border:0px solid #e0e0e0; padding: 20px; width: 60%; box-shadow: 0 4px 8px 0 rgba(0, 0, 0, 0.2);\">\n",
    "    <h3 style=\"margin-bottom:0px; padding-bottom:0px;\" >PyTorch Data Loader:</h3>\n",
    "    <p>\n",
    "        Here we create a Pytorch Data Loader to manage the training and test data. Torch DataLoaders work by xxxxxxx\n",
    "    </p>\n",
    "    <img style=\"height:500px;\" src=\"https://sebastianraschka.com/images/blog/2022/datapipes/loader-flow.png\"> </img>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Create Datasets\n",
    "<img src=\"https://www.civo.com/assets/public/machine-learning/gradient-divider-13b90e98503fdac947c77d8cdb6bf55f3af7186422ff7e4bea759e34eb5767c5.svg\"/> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the data transformations:\n",
    "# 1. Convert image data into PyTorch tensors.\n",
    "# 2. Normalize the image data with a given mean and standard deviation. \n",
    "#    This is specifically for MNIST where the mean is around 0.1307 and the standard deviation is around 0.3081.\n",
    "#    Normalizing helps in stabilizing the training process and makes the model less sensitive to the scale of the features.\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.1307,), (0.3081,))\n",
    "])\n",
    "\n",
    "# Define the training dataset:\n",
    "# 1. The MNIST dataset is loaded from the \"/data\" directory.\n",
    "# 2. If the dataset doesn't exist in the directory, it will be downloaded.\n",
    "# 3. The dataset will undergo the transformations defined above.\n",
    "dataset1 = datasets.MNIST('data/', train=True, download=True, transform=transform)\n",
    "\n",
    "# Define the test dataset (similar to the training dataset, but with `train=False` to load test data).\n",
    "dataset2 = datasets.MNIST('data/', train=False, transform=transform)\n",
    "\n",
    "# Create PyTorch DataLoaders:\n",
    "# DataLoaders provide a way to efficiently load data in batches, which is especially useful for training deep learning models.\n",
    "\n",
    "# Training DataLoader: Uses the training dataset and the training settings defined earlier.\n",
    "train_loader = torch.utils.data.DataLoader(dataset1, **train_kwargs)\n",
    "\n",
    "# Test DataLoader: Uses the test dataset and the test settings defined earlier.\n",
    "test_loader = torch.utils.data.DataLoader(dataset2, **test_kwargs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"font-family: 'Roboto', sans-serif; border:0px solid #e0e0e0; padding: 20px; width: 70%; box-shadow: 0 4px 8px 0 rgba(0, 0, 0, 0.2);\">\n",
    "    <h3 style=\"margin-bottom:0px; padding-bottom:0px;\" >Creating Dataset:</h3>\n",
    "    <p>\n",
    "        Here we show the input data type being segmented into output classifications.....XXXXXXX\n",
    "    </p>\n",
    "<div style=\"display: flex; align-items: center; padding: 10px;\">\n",
    "    <img src=\"https://raw.githubusercontent.com/jkotra/mnist-keras/master/mnist.png\" style=\"width:40%; border: 1px solid #ddd; padding: 10px;\">\n",
    "    <div style=\"font-size: 300px; line-height: 300px; width:20%; \">‚Üí</div>\n",
    "    <img src=\"https://miro.medium.com/v2/resize:fit:1400/format:webp/0*9jCey4wywZ4Os7hF.png\" style=\"width:40%; border: 1px solid #ddd; padding: 10px;\">\n",
    "</div></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Run Model\n",
    "<img src=\"https://www.civo.com/assets/public/machine-learning/gradient-divider-13b90e98503fdac947c77d8cdb6bf55f3af7186422ff7e4bea759e34eb5767c5.svg\"/> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the neural network model (defined previously as the Net class).\n",
    "# Move the model to the chosen computation device (either CPU, CUDA, or MPS).\n",
    "model = Net().to(device)\n",
    "\n",
    "# Specify an optimizer:\n",
    "# Adadelta is an adaptive learning rate method, which adapts over time and requires less manual tuning.\n",
    "# `model.parameters()` returns all the trainable parameters of the model.\n",
    "# Learning rate (lr) is specified from the args.\n",
    "optimizer = optim.Adadelta(model.parameters(), lr=args.lr)\n",
    "\n",
    "# Specify a scheduler for the learning rate:\n",
    "# StepLR adjusts the learning rate based on the number of epochs.\n",
    "# It reduces the learning rate by a factor of `gamma` every `step_size` epochs.\n",
    "scheduler = StepLR(optimizer, step_size=1, gamma=args.gamma)\n",
    "\n",
    "# Training loop:\n",
    "# For each epoch, the model is trained on the training data and then tested on the test data.\n",
    "# After each epoch, the scheduler adjusts the learning rate based on its configuration.\n",
    "for epoch in range(1, args.epochs + 1): \n",
    "    train(args, model, device, train_loader, optimizer, epoch)  # Train the model\n",
    "    test(model, device, test_loader)                            # Test the model\n",
    "    scheduler.step()                                            # Adjust the learning rate\n",
    "\n",
    "# If the `save_model` flag is set in args, save the trained model's state to a file named \"mnist_cnn.pt\".\n",
    "# This allows for loading the model later without having to retrain it.\n",
    "if args.save_model:\n",
    "    torch.save(model.state_dict(), \"mnist_cnn.pt\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
